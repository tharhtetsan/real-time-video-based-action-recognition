{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "data_path = r\"E:\\data_share_ths\\dataset\\UCF-101\\images\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['applyeyemakeup', 'applylipstick', 'archery'])\n",
      "115\n",
      "309\n",
      "158\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_labels  = {}\n",
    "images_folder_counts = {}\n",
    "\n",
    "\n",
    "for folder_name in os.listdir(data_path):\n",
    "    class_name = folder_name.split(\"_\")[1].lower()\n",
    "    image_paths = []\n",
    "    images_folder_counts[folder_name] = (len(os.listdir(data_path+\"\\\\\"+folder_name)))\n",
    "    for filename in os.listdir(data_path+\"\\\\\"+folder_name):\n",
    "        image_paths.append(data_path+\"\\\\\"+folder_name+\"\\\\\"+filename)\n",
    "    image_labels[class_name] = image_paths\n",
    "\n",
    "print(image_labels.keys())\n",
    "print(len(image_labels['applyeyemakeup']))\n",
    "print(len(image_labels['applylipstick']))\n",
    "print(len(image_labels['archery']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_interval = 5\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310\n",
      "159\n",
      "160\n"
     ]
    }
   ],
   "source": [
    "### Add label for black image \n",
    "real_label = []\n",
    "real_images =[]\n",
    "for className,image_paths in image_labels.items():\n",
    "    temp_img_path = image_paths\n",
    "    while len(temp_img_path)%img_interval != 0:\n",
    "        temp_img_path.append(\"-\")\n",
    "        print(len(temp_img_path))\n",
    "\n",
    "    image_labels[className] = temp_img_path\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['applyeyemakeup', 'applylipstick', 'archery'])\n",
      "115\n",
      "310\n",
      "160\n"
     ]
    }
   ],
   "source": [
    "print(image_labels.keys())\n",
    "print(len(image_labels['applyeyemakeup']))\n",
    "print(len(image_labels['applylipstick']))\n",
    "print(len(image_labels['archery']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :  435\n",
      "Y_train :  435\n",
      "X_test :  150\n",
      "Y_test :  150\n"
     ]
    }
   ],
   "source": [
    "# Create X_train,Y_train, X_test,Y_test\n",
    "test_amount = 50\n",
    "X_train,Y_train= [],[]\n",
    "X_test,Y_test = [],[]\n",
    "\n",
    "for className,image_paths in image_labels.items():\n",
    "    for i in range(len(image_paths)):\n",
    "        \n",
    "        if i < len(image_paths) - test_amount:\n",
    "            y_img_path = image_paths[i]\n",
    "            X_train.append(y_img_path)\n",
    "            Y_train.append([className])\n",
    "\n",
    "        else:\n",
    "            X_test.append(y_img_path)\n",
    "            Y_test.append([className])\n",
    "\n",
    "\n",
    "print(\"X_train : \",len(X_train))\n",
    "print(\"Y_train : \",len(Y_train))\n",
    "\n",
    "print(\"X_test : \",len(X_test))\n",
    "print(\"Y_test : \",len(Y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "CHANNEL = 3\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "OUTPUT_CHANNELS = 3\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGen(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, X_col, Y_col,\n",
    "                 batch_size,\n",
    "                 input_size=(224, 224, 3)):\n",
    "        self.X_col =X_col\n",
    "        self.Y_col =Y_col\n",
    "        self.batch_size = batch_size\n",
    "        self.n = len(self.X_col)\n",
    "\n",
    "    def read_img(self,path):\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img,(IMG_WIDTH,IMG_HEIGHT))\n",
    "        \n",
    "        #convert to tf and normalize\n",
    "        tf_img = tf.cast(img, tf.float32)\n",
    "        tf_img = (tf_img/127.5)-1\n",
    "        return tf_img\n",
    "    \n",
    "    def create_emptyImage(self):\n",
    "        img= np.zeros((IMG_WIDTH,IMG_HEIGHT,CHANNEL),dtype=int)\n",
    "        tf_img = tf.cast(img, tf.float32)\n",
    "        tf_img = (tf_img/127.5)-1\n",
    "        return tf_img\n",
    "\n",
    "\n",
    "\n",
    "    def __get_input(self, path):\n",
    "    \n",
    "        cur_img = None\n",
    "        if path ==\"-\":\n",
    "            cur_img = self.create_emptyImage()\n",
    "        else:\n",
    "            cur_img = self.read_img(path)\n",
    "\n",
    "        return cur_img\n",
    "    \n",
    "\n",
    "    \n",
    "    def __get_output(self, label):\n",
    "        return label\n",
    "    \n",
    "    def __get_data(self, x_batches, y_batches):\n",
    "        # Generates data containing batch_size samples\n",
    "        X_batchs = np.asarray([self.__get_input(x) for x in x_batches])\n",
    "        y_batches = np.asarray(self.__get_output(y_batches))\n",
    "        return X_batchs,y_batches\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        X_batches = self.X_col[index*self.batch_size : (index+1)*self.batch_size]\n",
    "        Y_batches = self.Y_col[index*self.batch_size : (index+1)*self.batch_size]\n",
    "        X,y= self.__get_data(X_batches,Y_batches)       \n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = CustomDataGen(X_col=X_train,Y_col=Y_train,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['applyeyemakeup']\n",
      " ['applyeyemakeup']\n",
      " ['applyeyemakeup']\n",
      " ['applyeyemakeup']\n",
      " ['applyeyemakeup']\n",
      " ['applyeyemakeup']\n",
      " ['applyeyemakeup']\n",
      " ['applyeyemakeup']]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "for img,label in test_gen:\n",
    "    print(label)\n",
    "    print(len(img))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tharhtet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b46ff7e5b8b7911cfa9955e23e477c53e63d207f4b9ab3253a6a5ac7336ecbe5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
